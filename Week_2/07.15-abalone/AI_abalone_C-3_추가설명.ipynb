{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c-3 에 있는 get_train_data() 함수의 내용 중 일부인  \n",
    "train_data = data[shuffle_map[mb_size*nth:mb_size*(nth+1)]] 에 대한 추가설명 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "------------------------------\n",
      "[[ 0.      1.      0.      0.455   0.365   0.095   0.514   0.2245  0.101\n",
      "   0.15   15.    ]\n",
      " [ 0.      1.      0.      0.35    0.265   0.09    0.2255  0.0995  0.0485\n",
      "   0.07    7.    ]\n",
      " [ 0.      0.      1.      0.53    0.42    0.135   0.677   0.2565  0.1415\n",
      "   0.21    9.    ]\n",
      " [ 0.      1.      0.      0.44    0.365   0.125   0.516   0.2155  0.114\n",
      "   0.155  10.    ]]\n",
      "------------------------------\n",
      "[[ 1.      0.      0.      0.555   0.43    0.155   0.7395  0.3135  0.1435\n",
      "   0.28   10.    ]\n",
      " [ 0.      1.      0.      0.39    0.28    0.125   0.564   0.3035  0.0955\n",
      "   0.143   7.    ]\n",
      " [ 0.      1.      0.      0.46    0.36    0.135   0.6105  0.1955  0.107\n",
      "   0.235  14.    ]\n",
      " [ 0.      1.      0.      0.425   0.33    0.13    0.4405  0.152   0.0935\n",
      "   0.155   9.    ]\n",
      " [ 0.      0.      1.      0.58    0.46    0.12    0.9935  0.4625  0.2385\n",
      "   0.28   11.    ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "with open('abalone.csv') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader, None)\n",
    "    rows = []\n",
    "    for row in csvreader:\n",
    "        rows.append(row)\n",
    "            \n",
    "global data, input_cnt, output_cnt\n",
    "input_cnt, output_cnt = 10, 1\n",
    "data = np.zeros([len(rows), input_cnt+output_cnt])\n",
    "\n",
    "for n, row in enumerate(rows):\n",
    "    if row[0] == 'I': data[n, 0] = 1\n",
    "    if row[0] == 'M': data[n, 1] = 1\n",
    "    if row[0] == 'F': data[n, 2] = 1\n",
    "    data[n, 3:] = row[1:]\n",
    "\n",
    "\n",
    "# 1 우선 shuffle_map을 생성시켜 봅니다. \n",
    "shuffle_map = np.arange(data.shape[0])\n",
    "print(shuffle_map[0:5])\n",
    "print(\"-\"*30)\n",
    "\n",
    "test_begin_idx = 31 * 100  #학습데이터와 테스트 데이터의 경계입니다\n",
    "#지금까지 shuffle_map은 0~n까지의 일반적인 순서입니다. \n",
    "\n",
    "\n",
    "# 2 data에 대해 일반적인 순서를 적용시키면  \n",
    "# 그 일반적인 순서에 맞게 출력하게 됩니다. \n",
    "test_data_1 = data[shuffle_map]\n",
    "print(test_data_1[0:4])\n",
    "\n",
    "\n",
    "# 3. shuffle_map에 저장되어 있는 인덱스(0~4177)를 처음(0)부터 test_begin_idx(3100)값 까지 만큼 범위를 지정하여 랜덤하게 섞어 줍니다. \n",
    "np.random.shuffle(shuffle_map[:test_begin_idx])\n",
    "\n",
    "\n",
    "# 4. data에 접근하여[shuffle_map랜덤하게 섞여있는 순서를 배치시킵니다.[그리고 0:100 까지의 범위만큼 선정하여]]  train_data에 저장해 줍니다\n",
    "train_data = data[shuffle_map[100*0:100*(0+1)]]\n",
    "print(\"-\"*30)\n",
    "\n",
    "# 5. 그럼 이렇게 train_data에 대하여 매번 다른 순서로 하여 값이 할당되게 됩니다. \n",
    "print(train_data[0:5])\n",
    "\n",
    "# 6.이 과정은 새로운 에폭마다 첫번째 미니배치가 실행될때 실행되는데, \n",
    "# 이렇게 학습데이터를 매번 무작위 인덱스 값으로 데이터로 할당하는 이유는 \n",
    "# 새로운 에폭이 실행될 때 마다 만약, 학습데이터가 계속 같은 순서로 미니배치처리 되면은 학습의 효율성이 떨어집니다. 그래서\n",
    "# 새로운 에폭이 실행될 때마다, 무작위 인덱스 값을 줘서 학습데이터를 모든 에폭마다 다르게 위치시켜 학습의 효율성을 높이려는 이유입니다.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
