{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 광주 인공지능 사관학교\n",
    "- - -\n",
    "- 작성자 : 2반 한지호\n",
    "- 작성일 : 20.07.15 수\n",
    "- 3교시 딥러닝 시간에 진행한 '전복 고리 수 추정' 예제 클론 코딩 실습\n",
    "- 단층 퍼셉트론의 이해를 위해 예제 코드를 강사님과 함께 보며 구조와 그 이유를 파악하였다.\n",
    "- A, B Line 까지 오늘 진행했고, 다음 수업시간 진도에 맞춰 추가 작성할 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flowchart](flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0 파이썬 모듈 불러들이기  \n",
    "- 이 예제는 단층 퍼셉트론의 기본 구조를 파악하기 위해 라이브러리 사용을 최소화한 예제다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 하이퍼 파라미터 정의  \n",
    "- 하이퍼 파라미터 : 고정값 (한 번의 실험 사이클 중간에 절대 변경 불가능한 값)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RND_MEAN = 0\n",
    "RND_STD = 0.0030\n",
    "\n",
    "LEARNING_RATE = 0.001 # 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 실험용 메인함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abalone_exec(epoch_count=10, mb_szie=10, report=1):\n",
    "    load_abalone_dataset() # 데이터를 불러들이는 함수\n",
    "    init_model() # 모델 초기화 함수\n",
    "    train_and_test(epoch_count, mb_szie, report) # 학습 및 테스트 수행 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 데이터 적재함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_abalone_dataset():\n",
    "    with open('abalone.csv') as f:\n",
    "        r = csv.reader(f)\n",
    "        next(r, None) # next()로 첫 행을 None으로 처리 (원하는 데이터만 출력 = 불필요한 정보를 처리)  \n",
    "        rows = []\n",
    "        for row in r:\n",
    "            rows.append(row)\n",
    "    \n",
    "    global data, input_count, output_count # 전역변수 생성\n",
    "    # 데이터의 입출력 벡터 정보 저장. 이후 크기 지정에 활용. \n",
    "    input_count, output_count = 10, 1 #원 핫(3) + 속성(7) = 10, 레이블 = 1\n",
    "    data = np.zeros(len(rows), input_count+output_count) \n",
    "    \n",
    "    # 원-핫 벡터 처리\n",
    "    # I = 1,0,0 / M = 0,1,0 / F = 0,0,1\n",
    "    for n, row in enumerate(rows):\n",
    "        # data[n, 0~3] = 성별 정보 원 핫 벡터 처리 / 이후 데이터(속성)는 그 뒤에 그대로 복사\n",
    "        if row[0] == 'I': \n",
    "            data[n, 0] = 1 \n",
    "        if row[0] == 'M': \n",
    "            data[n, 1] = 1 \n",
    "        if row[0] == 'F': \n",
    "            data[n, 2] = 1 \n",
    "        data[n, 3:] = row[1:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 파라미터 초기화 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    global weight, bias, input_count, output_count # 전역변수 불러오기 및 생성\n",
    "    weight = np.random.normal(RND_MEAN, RND_STD, [input_count, output_count]) # 가중치 초기화 : 정규분포를 갖는 난수 생성\n",
    "    bias = np.zeros([output_count]) # 편향 0으로 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3 학습 및 평가 함수 정의\n",
    "- 1 epoch = 1 batch (= N mini batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch_count, mb_size, report):\n",
    "    step_count = arrange_data(mb_size) \n",
    "    test_x, test_y = get_test_data() \n",
    "    \n",
    "    for epoch in range(epoch_count): # epoch_count 만큼 epoch 반복 수행\n",
    "        losses, accs = [], [] # 한 차례의 epoch마다 손실과 정확도 저장\n",
    "        \n",
    "        for n in range(step_count): # 학습 데이터 크기에 비례하여 (80%) 미니배치 처리된 횟수 만큼 반복 수행\n",
    "            train_x, train_y = get_train_data(mb_size, n) # 미니배치 마다의 학습 데이터 분할\n",
    "            loss, acc = run_train(train_x, train_y) # 학습 수행 및 손실과 정확도 산출\n",
    "            # 미니배치 처리 이후 손실과 정확도를 누적하여 저장 (이후 이 값들을 평균내면 한차례의 'epoch' 처리) \n",
    "            losses.append(loss) \n",
    "            accs.append(acc) \n",
    "            \n",
    "        if report > 0 and (epoch+1) % report == 0: # 출력 주기 및 테스트 주기 설정\n",
    "            acc = run_test(test_X, test_y) # 테스트 데이터로 테스트 진행\n",
    "            print(f'Epoch {epoch+1}: loss={np.mean(losses):5.3f}, accuracy={np.mean(accs):5.3f}/{acc:5.3f}')\n",
    "            \n",
    "        final_acc = run_test(test_x, test_y) # 모든 반복이 종료되었을 때, 한 번 더 최종 결과 출력\n",
    "        print(f'\\nFinal Test: final accuracy = {final_acc:5.3f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
