{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07.30-preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-m0W5xCOyXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c4bf695d-924d-4eef-b587-9519436d0c8c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr6HlbP5Omil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAbpqiwpsnp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "imdb_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/ai_school/data/IMDB Dataset.csv\")\n",
        "# print(imdb_data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WN__2o6TsY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pos, neg 값을 숫자로 변형\n",
        "imdb_data['sentiment'] = imdb_data['sentiment'].replace(\"positive\", 1)\n",
        "# 위는 'imdb_data['sentiment'].replace(\"positive\", 1, inplace=True)'와 같음\n",
        "imdb_data['sentiment'] = imdb_data['sentiment'].replace(\"negative\", 0)\n",
        "# print(imdb_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32MiDXDUTwmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "18ef3ef5-b806-4a6b-e2cb-2aa1963e1cea"
      },
      "source": [
        "# 단어 아니면 삭제 (정규 표현식 사용)\n",
        "imdb_data['review'] = imdb_data['review'].str.replace(\"[^\\w]|br\", \" \")\n",
        "print(imdb_data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  review  sentiment\n",
            "0      One of the other reviewers has mentioned that ...          1\n",
            "1      A wonderful little production            The f...          1\n",
            "2      I thought this was a wonderful way to spend ti...          1\n",
            "3      Basically there s a family where a little boy ...          0\n",
            "4      Petter Mattei s  Love in the Time of Money  is...          1\n",
            "...                                                  ...        ...\n",
            "49995  I thought this movie did a down right good job...          1\n",
            "49996  Bad plot  bad dialogue  bad acting  idiotic di...          0\n",
            "49997  I am a Catholic taught in parochial elementary...          0\n",
            "49998  I m going to have to disagree with the previou...          0\n",
            "49999  No one expects the Star Trek movies to be high...          0\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt0inxFFUybx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15af4802-982a-4b39-b5f1-ef7f16caa35d"
      },
      "source": [
        "# 혹시 공백이 있으면 null array로 (ex : 이모티콘만 사용해서 다 지워진 행)\n",
        "imdb_data['review'] = imdb_data['review'].replace('', np.nan)\n",
        "imdb_data['sentiment'] = imdb_data['sentiment'].replace('', np.nan)\n",
        "# null array 모두 제거 (공백인 열 모두 제거)\n",
        "imdb_data = imdb_data.dropna(how='any')\n",
        "\n",
        "print(\"# preproecssing done\") # 눈으로 진행도를 확인하기 위한 출력 (필수 X))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# preproecssing done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO3D1cxDVFYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a653849-ef1d-45be-9379-847701507311"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "review_train, review_test, y_train, y_test = train_test_split(imdb_data['review'], imdb_data['sentiment'], test_size=0.25, shuffle=False, random_state=1004)\n",
        "\n",
        "print('# split done')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# split done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I88Wa77uVJZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96c520a5-6370-4647-cd7c-e4d4b82fe9b8"
      },
      "source": [
        "# stopwords 지정 (예시)\n",
        "stopwords = ['a', 'an']\n",
        "\n",
        "# 토큰화 진행 (시간 관계상 스플릿으로 진행, 더 높은 정확도를 원한다면 토크나이저 사용)\n",
        "X_train = []\n",
        "for stc in review_train:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_train.append(token)\n",
        "\n",
        "X_test = []\n",
        "for stc in review_test:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_test.append(token)\n",
        "\n",
        "print('# tokenization done')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# tokenization done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVOqhxISVMEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# X_train 단어들을 토대로 정수 인덱스 설정 (단어를 정수형태로 변환), 전체 단어 갯수 설정\n",
        "# tensorflow의 임베딩은 무조건 정수 형태로만 input을 받는다.\n",
        "# 왜 트레인셋만?.. 원한다면 처음에 test/train 스플릿하기 전에, 전처리해서 fit해도 무방\n",
        "# 왜 5000?.. 유의미한 단어 갯수를 생각해보자! \n",
        "# 빈도수가 1~2개인 단어 버려도 큰 영향을 끼치지 않을것 -> count함수써서 빈도수 낮은 것들을 버리고, 남은 단어의 갯수들\n",
        "# 즉, 빈도수 1개다 -> 버리자, 빈도수 2개다 -> 버리자\n",
        "tokenizer = Tokenizer(5000) # 토크나이저이 인자값을 넣으면 그 만큼만 인덱스를 생성하고 나머지는 잘라버림\n",
        "\n",
        "# train 을 기준으로 단어마다의 인덱스를 부여\n",
        "tokenizer.fit_on_texts(X_train) #  X_train을 스플릿 하기 전에 토큰화 한 것으로 넣어도 가능 "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqCxImKCVNqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed0c80b0-a521-4933-a712-2524ce156fe0"
      },
      "source": [
        "# 위에서 설정된 정수 인덱스를 토대로 변환\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "print('# int_encoding done')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# int_encoding done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeUPP8Gk69bN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c1fdd2b6-df39-4aaa-bf5d-58541ac5471a"
      },
      "source": [
        "print(X_train[1])\n",
        "print(y_train[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[106, 387, 118, 357, 1, 1364, 3016, 5, 51, 51, 158, 54, 2198, 1550, 2, 409, 2, 527, 277, 3, 1847, 4, 1, 444, 408, 1, 150, 24, 566, 67, 2206, 494, 4098, 22, 60, 44, 192, 29, 1, 17, 23, 44, 29, 1, 2316, 176, 3408, 95, 19, 48, 371, 61, 1, 795, 32, 1, 1848, 4, 1798, 22, 60, 5, 6, 67, 273, 1, 147, 17, 6, 5, 412, 2, 2441, 408, 106, 4391, 357, 42, 27, 3, 1, 79, 1146, 11, 3, 201, 2, 25, 113, 1, 1847, 63, 267, 348, 15, 1, 118, 179, 1, 1030, 3, 1, 2791, 59, 249, 72, 356, 1, 2210, 960, 3198, 1249, 1202, 89, 4982, 6, 304, 21, 256, 1864, 2, 256, 4320, 572, 15, 1, 134, 3643, 2, 2, 1, 712, 572, 3, 64, 1047, 15, 11, 171, 2348, 24, 2010, 67, 218]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvR2qIhBT1CF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문장(데이터) 길이를 맞춰준다 \n",
        "# 임의로 맞추는게 아니고, 데이터셋을 보면서 최대 문장의 길이가 얼마인지 확인하고 거기에 맞춰서\n",
        "max_len = 500 \n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKapMUZA7Hc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "de2ca34a-0f38-4fe5-f9a9-6b7138c62d99"
      },
      "source": [
        "print(X_train[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0  106  387  118  357    1 1364 3016    5\n",
            "   51   51  158   54 2198 1550    2  409    2  527  277    3 1847    4\n",
            "    1  444  408    1  150   24  566   67 2206  494 4098   22   60   44\n",
            "  192   29    1   17   23   44   29    1 2316  176 3408   95   19   48\n",
            "  371   61    1  795   32    1 1848    4 1798   22   60    5    6   67\n",
            "  273    1  147   17    6    5  412    2 2441  408  106 4391  357   42\n",
            "   27    3    1   79 1146   11    3  201    2   25  113    1 1847   63\n",
            "  267  348   15    1  118  179    1 1030    3    1 2791   59  249   72\n",
            "  356    1 2210  960 3198 1249 1202   89 4982    6  304   21  256 1864\n",
            "    2  256 4320  572   15    1  134 3643    2    2    1  712  572    3\n",
            "   64 1047   15   11  171 2348   24 2010   67  218]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fJkyubNUBo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 레이어들을 쌓을 모델을 생성\n",
        "model = Sequential()\n",
        "# 단어를 임베딩하는데, 5000개의 단어를 120차원으로 내보내겠다\n",
        "# Emdedding의 인자값 : 1인자 = 내가 넣을 단어의 갯수 (총 인덱스의 갯수), 2인자 = 출력할 차원 (덴스 벡터의 차원), 3인자 = 문장의 길이\n",
        "model.add(Embedding(5000, 120)) # Embedding의 인자값에 위에서 설정한 max_len인 'input_length = 500' 이 생략된 상태\n",
        "# RNN - simpleRNN / LSTM\n",
        "model.add(LSTM(120))\n",
        "# 긍정/부정을 판단하니까 이진 분류 -> sigmoid 함수 사용\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgE9kg9MUh3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 혹시 5회 이상 검증데이터 loss가 증가하면, 과적합될 수 있으므로 학습을 조기종료!\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "# 훈련을 거듭하면서, 가장 검증데이터 정확도가 높았던 순간을 체크포인트로 저장\n",
        "model_check = ModelCheckpoint('the_best.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaWnqz8vUikT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d8bdb4f5-8faf-4ec1-e925-b037d1cffac3"
      },
      "source": [
        "# 긍정/부정을 판단하니까 손실함수는 이진 교차 엔트로피, 최적화는 adam, 평가 기준은 acc (출력할때 뜬다)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=64, callbacks=[early_stop, model_check])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "586/586 [==============================] - ETA: 0s - loss: 0.3987 - acc: 0.8154\n",
            "Epoch 00001: val_acc improved from -inf to 0.82968, saving model to the_best.h5\n",
            "586/586 [==============================] - 534s 910ms/step - loss: 0.3987 - acc: 0.8154 - val_loss: 0.3990 - val_acc: 0.8297\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f42e9bce550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeN75BrjUt2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fb7eeae1-d15d-4915-81ca-ef010e30ea7e"
      },
      "source": [
        "# 정확도 측정 / 출력하면 [loss, acc]\n",
        "print(model.evaluate(X_test, y_test))\n",
        "# X 값은 전처리, 토큰화, 정수인코딩이 된 상태의 문장이어야 한다\n",
        "# print(model.predict(X))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 42s 108ms/step - loss: 0.3990 - acc: 0.8297\n",
            "[0.39899691939353943, 0.8296800255775452]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}