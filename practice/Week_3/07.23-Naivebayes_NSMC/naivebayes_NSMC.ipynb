{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 광주 인공지능 사관학교\n",
    "- - -\n",
    "- 작성자 : 2반 한지호\n",
    "- 작성일 : 20.07.23 목\n",
    "- 4교시 자연어 처리 시간에 진행한 NSMC의 ratings.txt 데이터를 이용한 나이브 베이즈 분류기 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from math import log, exp\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    train_datas = open_txt() \n",
    "    test_data = input() \n",
    "    prob = naive_bayes(train_datas, test_data, 0.5, 0.5) \n",
    "\n",
    "    print(f'{test_data}가 부정적일 확률 : {prob[0]}, 긍정적일 확률 : {prob[1]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_txt():\n",
    "    f = open('ratings.txt', 'r', encoding='utf-8')\n",
    "\n",
    "    pos_doc = []\n",
    "    neg_doc = [] \n",
    "    \n",
    "    for line in f:\n",
    "        a = line.replace('\\n', '')\n",
    "        b = a.split('\\t')\n",
    "        if b[2] == '1':\n",
    "            pos_doc.append(b[1])\n",
    "        else:\n",
    "            neg_doc.append(b[1])\n",
    "\n",
    "    train_datas = [[], []]\n",
    "    train_datas[0] = neg_doc\n",
    "    train_datas[1] = pos_doc\n",
    "\n",
    "    return [' '.join(train_datas[0]), ' '.join(train_datas[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_doc_prob(train_data, test_data, nowords_weight):\n",
    "    sw_train_data = re.compile('[^\\w]').sub(' ', train_data.lower())\n",
    "    sw_train_token = sw_train_data.split()\n",
    "    train_vector = dict(Counter(sw_train_token))\n",
    "\n",
    "    sw_test_data = re.compile('[^\\w]').sub(' ', test_data.lower())\n",
    "    sw_test_token = sw_test_data.split()\n",
    "    test_vector = dict(Counter(sw_test_token))\n",
    "\n",
    "    log_prob = 0\n",
    "\n",
    "    total_wc = len(sw_train_token)\n",
    "\n",
    "    for word in test_vector:\n",
    "        if word in train_vector:\n",
    "            log_prob += log(train_vector[word]/total_wc)\n",
    "        else:\n",
    "            log_prob += log(nowords_weight/total_wc)\n",
    "\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(train_datas, test_data, pos_prob, neg_prob):\n",
    "    test_pos_prob = calculate_doc_prob(train_datas[1], test_data, 0.1) + log(pos_prob) \n",
    "    test_neg_prob = calculate_doc_prob(train_datas[0], test_data, 0.1) + log(neg_prob) \n",
    "\n",
    "    maxprob = max(test_neg_prob, test_pos_prob)\n",
    "    test_pos_prob -= maxprob\n",
    "    test_neg_prob -= maxprob\n",
    "    test_pos_prob = exp(test_pos_prob)\n",
    "    test_neg_prob = exp(test_neg_prob)\n",
    "    \n",
    "    normalized_prob = [test_neg_prob/(test_pos_prob+test_neg_prob), test_pos_prob/(test_pos_prob+test_neg_prob)]\n",
    "\n",
    "    return normalized_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개별로\n",
      "개별로가 부정적일 확률 : 0.9510135732732697, 긍정적일 확률 : 0.04898642672673021\n"
     ]
    }
   ],
   "source": [
    "start() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
