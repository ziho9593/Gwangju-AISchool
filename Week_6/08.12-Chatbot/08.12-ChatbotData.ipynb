{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ChatbotData.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"I2FWm0SKKZ_J","colab_type":"code","colab":{}},"source":["import numpy as np\n","import re\n","import pandas as pd\n","import csv\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yCK8tWLxSONN","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"03bl3S5qqZrC","colab_type":"code","colab":{}},"source":["chatbot = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/ai_school/data/ChatbotData .csv\")\n","\n","chatbot['Q'] = chatbot['Q'].str.replace(\"[^\\w]\", \" \")\n","chatbot['A'] = chatbot['A'].str.replace(\"[^\\w]\", \" \")\n","\n","print(chatbot)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldgDJJZgqytI","colab_type":"code","colab":{}},"source":["encoder_input, decoder_input, decoder_output = [], [], []\n","\n","for stc in chatbot['Q']:\n","    encoder_input.append(stc.split())\n","\n","for stc in chatbot['A']:\n","    decoder_input.append((\"<start> \"+stc).split())\n","\n","for stc in chatbot['A']:\n","    decoder_output.append((stc+\" <end>\").split())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9YqTq0f4rVNW","colab_type":"code","colab":{}},"source":["tokenizer_q = Tokenizer()\n","tokenizer_q.fit_on_texts(encoder_input)\n","encoder_input = tokenizer_q.texts_to_sequences(encoder_input)\n","\n","tokenizer_a = Tokenizer()\n","tokenizer_a.fit_on_texts(decoder_input)\n","tokenizer_a.fit_on_texts(decoder_output)\n","decoder_input = tokenizer_a.texts_to_sequences(decoder_input)\n","decoder_output = tokenizer_a.texts_to_sequences(decoder_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITAo3Ecirn4v","colab_type":"code","colab":{}},"source":["encoder_input = pad_sequences(encoder_input, padding=\"post\")\n","decoder_input = pad_sequences(decoder_input, padding=\"post\")\n","decoder_output = pad_sequences(decoder_output, padding=\"post\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9LHYsgNrsGr","colab_type":"code","colab":{}},"source":["print(encoder_input[:3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y2ugiyfMr1rU","colab_type":"code","colab":{}},"source":["print(encoder_input.shape)\n","print(decoder_input.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kxQh4t2hr6rI","colab_type":"code","colab":{}},"source":["a_to_index = tokenizer_a.word_index\n","index_to_a = tokenizer_a.index_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qBbXzoPUsF17","colab_type":"code","colab":{}},"source":["test_size = 2500\n","encoder_input_train = encoder_input[:-test_size]\n","decoder_input_train = decoder_input[:-test_size]\n","decoder_output_train = decoder_output[:-test_size]\n","\n","encoder_input_test = encoder_input[-test_size:]\n","decoder_input_test = decoder_input[-test_size:]\n","decoder_output_test = decoder_output[-test_size:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0DVSJxA9sLKi","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"nn-kjwNssLwu","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n","from tensorflow.keras.models import Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6DJkWSzusOuv","colab_type":"code","colab":{}},"source":["encoder_inputs = Input(shape=(15,))\n","encoder_embed = Embedding(len(tokenizer_q.word_index)+1, 50)(encoder_inputs)\n","encoder_mask = Masking(mask_value=0)(encoder_embed)\n","encoder_outputs, h_state, c_state = LSTM(50, return_state=True)(encoder_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1N9usf3sdCM","colab_type":"code","colab":{}},"source":["decoder_inputs = Input(shape=(22,))\n","decoder_embed = Embedding(len(tokenizer_a.word_index)+1, 50)(decoder_inputs)\n","decoder_mask = Masking(mask_value=0)(decoder_embed)\n","\n","decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state])\n","\n","decoder_dense = Dense(len(tokenizer_a.word_index)+1, activation='softmax')\n","decoder_softmax_outputs = decoder_dense(decoder_outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UN-PbzSns7bt","colab_type":"code","colab":{}},"source":["model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n","model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n","model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_output_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_output_test), batch_size = 128, epochs = 20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iN-yy4IvtS6E","colab_type":"text"},"source":["# Prediction"]},{"cell_type":"code","metadata":{"id":"FIA4caoxtTew","colab_type":"code","colab":{}},"source":["encoder_model = Model(encoder_inputs, [h_state, c_state])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6AI9CQAtcs6","colab_type":"code","colab":{}},"source":["encoder_h_state = Input(shape=(50,))\n","encoder_c_state = Input(shape=(50,))\n","\n","pd_decoder_outputs, pd_h_state, pd_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_h_state, encoder_c_state])\n","pd_decoder_softmax_outputs = decoder_dense(pd_decoder_outputs)\n","\n","decoder_model = Model([decoder_inputs, encoder_h_state, encoder_c_state], [pd_decoder_softmax_outputs, pd_h_state, pd_c_state])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mvZUe4lUuYBb","colab_type":"code","colab":{}},"source":["input_stc = input()\n","token_stc = input_stc.split()\n","encode_stc = tokenizer_q.texts_to_sequences([token_stc])\n","pad_stc = pad_sequences(encode_stc, maxlen=15, padding=\"post\")\n","\n","states_value = encoder_model.predict(pad_stc)\n","\n","predicted_seq = np.zeros((1,1))\n","predicted_seq[0, 0] = a_to_index['<start>']\n","print(predicted_seq)\n","\n","decoded_stc = []\n","\n","while True:\n","    output_words, h, c = decoder_model.predict([predicted_seq] + states_value)\n","\n","    predicted_word = index_to_a[np.argmax(output_words[0,0])]\n","\n","    if predicted_word == '<end>':\n","        break\n","\n","    decoded_stc.append(predicted_word)\n","\n","    predicted_seq = np.zeros((1,1))\n","    predicted_seq[0,0] = np.argmax(output_words[0,0])\n","\n","    states_value = [h, c]\n","\n","print(' '.join(decoded_stc))"],"execution_count":null,"outputs":[]}]}