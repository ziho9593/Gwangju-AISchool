{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08.10-seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOEz8JjR-gQj",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDSFztmqkoZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUcPEgb_Th93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "ce4e4c80-38f2-4371-f6e2-fb5f08a55561"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WnVchVxaSF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dfd5fee-9238-43a7-98ca-e10ce4520223"
      },
      "source": [
        "# 파일 불러와서 약간의 전처리\n",
        "\n",
        "files = open(\"/content/drive/My Drive/Colab Notebooks/ai_school/data/par_corp.csv\")\n",
        "\n",
        "re_lines = []\n",
        "for line in files:\n",
        "    if line[0] == '[': # '[1], [2], ...' 의 형태로 된 인덱스 행들을 스킵한다.\n",
        "        continue\n",
        "    re_line = re.sub('[#\".?!\\n]', '', line)\n",
        "    re_lines.append(re_line)\n",
        "\n",
        "print(re_lines[:4]) # [영어, 한글, 영어, 한글, ...]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The order went forth that', '명령은 아래와 같이 반포되었다', 'The orders must be strictly obeyed', '명령은 반드시 엄격히 준수해야 한다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZFJMYWiTdOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "7b0b249e-32a2-4751-b5dc-e5f95e98ff2c"
      },
      "source": [
        "kor = []\n",
        "eng = []\n",
        "count = 0\n",
        "\n",
        "for line in re_lines:\n",
        "    count = count + 1\n",
        "    if count % 2 == 0:\n",
        "        kor.append(line) # 짝수는 한글 -> kor 리스트에 추가\n",
        "    else:\n",
        "        eng.append(line) # 홀수는 영어 -> eng 리스트에 추가\n",
        "\n",
        "d = {'kor':kor, 'eng':eng} # kor, eng 리스트를 딕셔너리 형태로 변환\n",
        "\n",
        "par_corp = pd.DataFrame(d) # 딕셔너리를 데이터 프레임으로 변환\n",
        "\n",
        "print(par_corp)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          kor                                        eng\n",
            "0            명령은 아래와 같이 반포되었다                  The order went forth that\n",
            "1         명령은 반드시 엄격히 준수해야 한다         The orders must be strictly obeyed\n",
            "2       운명의 여신은 용사를 특별히 애호하신다                  fortune favors the brave \n",
            "3         운명에 그가 죽을 것이라고 정해졌다            Fate destined that he shall die\n",
            "4      운명에 그는 목사가 될 것이라고 정해졌다         Fate had ordained him to die young\n",
            "...                       ...                                        ...\n",
            "47662              사자는 야생동물이다                  The lion is a wild animal\n",
            "47663            사자는 황야로 도망갔다  The lion escaped and returned to the wild\n",
            "47664   사자는 우리 안에서 천천히 왔다갔다한다       The lion paced the floor of its cage\n",
            "47665   젖은 셔츠가 그의 몸에 착 달라붙어있다            The wet shirt clung to his body\n",
            "47666      젖은 성냥은 그어도 켜지지 않는다                  Damp matches won't strike\n",
            "\n",
            "[47667 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqcW5goHuRSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문장 토큰화 (스탑워드 제거) -> 단어 별로 나누기 위해서\n",
        "# 정수 인코딩 -> 컴퓨터가 잘 알아들을수 있도록 단어로 된거를 숫자로 변형\n",
        "# 패딩 -> embedding layer를 통과하려면 벡터의 길이가 같아야하기 때문에\n",
        "\n",
        "# '<start> i am taking a walk with my dog'\n",
        "# -> 각 시점마다 이 문장의 일부분을 decoder_output을 추측하는데 사용하고 있음\n",
        "# 'i am taking a walk with my dog <end>'\n",
        "\n",
        "encoder_input, decoder_input, decoder_output = [], [], []\n",
        "\n",
        "# 왜 디코더는 인풋/아웃풋 둘 다 존재하는가?\n",
        "# 예를 들어, '나는 개와 산책을 하고 있다'라는 문장이 있을 때 -> 인코더를 거치면서 셀/은닉 상태 리턴\n",
        "# 위 문장의 '셀 상태'와 '은닉 상태' + '<start>' 가 인풋으로 들어가면,\n",
        "# 지금까지 쌓아진 셀/은닉 상태 값, 현재 단어 출력 -> 다음 단어 예측에 사용\n",
        "# 여기서 <start>가 예측한 단어는 <start> 바로 다음 단어 (예측 문장의 첫 단어)\n",
        "\n",
        "# 훈련을 시키고나서 예측을 하려고 할 때 (상태값이 없다면) <start> 뒤에는 굉장히 다양한 단어가 올 수 있음\n",
        "# <start> 는 뒤에 어떤 단어든지 올 수 있는 단어의 역할\n",
        "# 상태값을 함께 고려하도록 해주면, 모든 단어들 중에서 상태값에 연관되어있는 것만 높을 확률을 부여\n",
        "# 그렇게 예측한 바로 전 단어를 기준으로 다음 단어의 예측을 반복\n",
        "# 다음 단어로 <end>가 예측된다면, 이제 그만 예측하라는 뜻\n",
        "\n",
        "# '<start> i am taking a walk with my dog'\n",
        "# -> 각 시점마다 이 문장의 일부분을 decoder_output의 일부분을 추측하는데 사용하고 있음\n",
        "# 'i am taking a walk with my dog <end>'\n",
        "\n",
        "for stc in par_corp['kor']:\n",
        "    encoder_input.append(stc.split())\n",
        "\n",
        "# 스타트 뒤에 띄어쓰기 :<start>도 split 해줘야 하기 때문\n",
        "# ex) ['<start>', 'i', 'am', 'taking']\n",
        "for stc in par_corp['eng']:\n",
        "    decoder_input.append((\"<start> \"+stc).split())\n",
        "\n",
        "# 엔드도 스타트와 마찬가지\n",
        "for stc in par_corp['eng']:\n",
        "    decoder_output.append((stc+\" <end>\").split())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATd4nvS2FLZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e032d4b5-fba0-4c83-ff1c-59561a2117bd"
      },
      "source": [
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['명령은', '아래와', '같이', '반포되었다'], ['명령은', '반드시', '엄격히', '준수해야', '한다'], ['운명의', '여신은', '용사를', '특별히', '애호하신다']]\n",
            "[['<start>', 'The', 'order', 'went', 'forth', 'that'], ['<start>', 'The', 'orders', 'must', 'be', 'strictly', 'obeyed'], ['<start>', 'fortune', 'favors', 'the', 'brave']]\n",
            "[['The', 'order', 'went', 'forth', 'that', '<end>'], ['The', 'orders', 'must', 'be', 'strictly', 'obeyed', '<end>'], ['fortune', 'favors', 'the', 'brave', '<end>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRtGMp3KvvT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_ko = Tokenizer()\n",
        "tokenizer_ko.fit_on_texts(encoder_input)\n",
        "encoder_input = tokenizer_ko.texts_to_sequences(encoder_input)\n",
        "\n",
        "# 만약에 Tokenizer(5000)이면, 1~4999(패딩하기 전) -> 0~4999(패딩하고 난 뒤)\n",
        "# 즉, 빈도수 순서로 1~4999 까지의 인덱스를 부여한 후, 남는 길이만큼 0을 채운다.\n",
        "tokenizer_en = Tokenizer()\n",
        "tokenizer_en.fit_on_texts(decoder_input)\n",
        "tokenizer_en.fit_on_texts(decoder_output)\n",
        "# 정수 인코딩 (1부터 인덱스를 부여하는 부분)\n",
        "decoder_input = tokenizer_en.texts_to_sequences(decoder_input)\n",
        "decoder_output = tokenizer_en.texts_to_sequences(decoder_output)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LN3mt7F94V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "324acd85-a38b-40ca-a87c-8cdb92533cab"
      },
      "source": [
        "# 2와 3이 start와 end 역할을 하는 것을 확인 할 수 있다.\n",
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10325, 1216, 312, 23138], [10325, 66, 8026, 6543, 12], [8027, 23139, 23140, 1162, 23141]]\n",
            "[[2, 1, 175, 97, 670, 19], [2, 1, 761, 78, 31, 2133, 11983], [2, 1324, 6699, 1, 2852]]\n",
            "[[1, 175, 97, 670, 19, 3], [1, 761, 78, 31, 2133, 11983, 3], [1324, 6699, 1, 2852, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1hcwCmuwhtp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "66485914-7e9d-4aad-c941-6e2ce0142220"
      },
      "source": [
        "# 문장 길이 체크\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "len_ko = []\n",
        "for data in encoder_input:\n",
        "    len_ko.append(len(data))\n",
        "\n",
        "len_en = []\n",
        "for data in decoder_input:\n",
        "    len_en.append(len(data))\n",
        "\n",
        "plt.hist(len_ko, label='ko', alpha=0.7)\n",
        "plt.hist(len_en, label='en', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5PXZxh2xiCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# maxlen을 굳이 명시하지 않아도 알아서 잘 해준다.\n",
        "# padding=\"post\" -> 문장은 단어가 이어지는게 중요하기 때문에 앞에서 부터 단어를 넣고 뒤에 0을 채우도록 해준다.\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "decoder_output = pad_sequences(decoder_output, padding=\"post\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hll0xCIbaQSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dfbe6709-7f18-49e5-ed1d-4403c8c2b62d"
      },
      "source": [
        "# 실제 최대 길이인 27에 맞춰진 것을 확인 가능\n",
        "print(encoder_input.shape)\n",
        "print(decoder_input.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47667, 27)\n",
            "(47667, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Fjxoc_yEhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 나중에 prediction 할때 사용하기 위함 (인덱스로 단어 찾기)\n",
        "en_to_index = tokenizer_en.word_index\n",
        "index_to_en = tokenizer_en.index_word"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tHcgptHyW4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 훈련, 테스트 데이터 나누기\n",
        "test_size = 12000 # 총 데이터가 47667개 아므로, 약 3대 1의 비율\n",
        "\n",
        "encoder_input_train = encoder_input[:-test_size]\n",
        "decoder_input_train = decoder_input[:-test_size]\n",
        "decoder_output_train = decoder_output[:-test_size]\n",
        "\n",
        "encoder_input_test = encoder_input[-test_size:]\n",
        "decoder_input_test = decoder_input[-test_size:]\n",
        "decoder_output_test = decoder_output[-test_size:]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15K1bAFh9qFD",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2FIv4T0zFJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju_5mWXqzIiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더 모델 - 한글 문장 받아서 LSTM 마지막 시점의 은닉상태/셀상태 리턴하도록\n",
        "\n",
        "# 원래는 데이터 갯수랑 문장 길이 같이 들어가야하지만, 왜 여기선 데이터 갯수는 명시하지 않을까?\n",
        "# 그 이유는, fit 할때 validation data -> test set -> 데이터 갯수 다르기 때문에\n",
        "encoder_inputs = Input(shape=(27,)) # 27은 문장의 길이\n",
        "\n",
        "# 1을 더해주는 이유는 패딩하면서 생긴 0을 처리해주기 위함\n",
        "# 예를 들어, Tokeninzer(5000)은 1 부터 4999 까지 인덱스 부여하기 때문\n",
        "encoder_embed = Embedding(len(tokenizer_ko.word_index)+1, 50)(encoder_inputs)\n",
        "\n",
        "# 사실 패딩 값은 필요없다. (0에 해당하는 임베딩 벡터 제외)\n",
        "encoder_mask = Masking(mask_value=0)(encoder_embed)\n",
        "\n",
        "# return_state=True 를 쓰면 '마지막 은닉 상태', '마지막 은닉 상태', '마지막 셀 상태'의 총 3개 리턴\n",
        "# LSTM 셀 자체에서 한 시점의 출력은 은닉 상태값 (softmax 함수를 통과하면서 y값)\n",
        "# encoder_outputs는 마지막 은닉 상태 값, h_state도 마지막 은닉 상태 값, 즉 encoder_outputs == h_state\n",
        "encoder_outputs, h_state, c_state = LSTM(50, return_state=True)(encoder_mask)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXaPcHYY1BCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더 모델 - 위에서 리턴한 상태값(h_state, c_state)과 영어 문장 입력받아서\n",
        "# LSTM이 출력한 값(은닉 상태)을 받아서 softmax 함수를 통과시키도록\n",
        "\n",
        "decoder_inputs = Input(shape=(27,)) # 27은 영어 문장의 길이\n",
        "decoder_embed = Embedding(len(tokenizer_en.word_index)+1, 50)(decoder_inputs)\n",
        "decoder_mask = Masking(mask_value=0)(decoder_embed)\n",
        "\n",
        "# return_sequences=True 를 쓰면 전체 시점의 은닉 상태 값을 리턴 -> 각 단어 인풋 별로 나오는 은닉 상태값\n",
        "# return_state=True 까지 둘 다 쓰면, 전체 시점의 은닉 상태(단어 갯수 만큼) / 마지막 은닉 상태 / 마지막 셀 상태 값을 리턴\n",
        "# -> 훈련 땐 필요 없지만, Prediction에서 다음 단어 예측을 위해 return_state도 True로 설정한다.\n",
        "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
        "\n",
        "# decoder_outputs는 전체 시점의 은닉 상태 값\n",
        "# decoder는 마지막 시점의 은닉/셀 상태 값이 중요하지 않기 때문에 _로 처리\n",
        "# initial_state : 인코더의 마지막 은닉/셀 상태 값이 디코더의 초기 상태 값으로 입력\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state]) \n",
        "\n",
        "# 전체 단어중 가장 높은 확률값을 얻어야해서, 임베딩과 동일하게 0을 고려하여 인덱스의 수에 1을 더해 전체 단어 갯수만큼 차원을 설정 \n",
        "# 패딩을 한 후의 지금 0 ~ 단어 갯수 -> 수를 가진 decoder_input/output\n",
        "# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, ..., 단어 갯수 만큼] -> array\n",
        "# [0번째 인덱스의 단어가 다음단어일 확률, 1번째 인덱스의 단어가 다음단어일 확률, 0.2, 0.3, ..., 단어 갯수] (지금 input으로 들어간 단어의 다음 단어일 확률값)\n",
        "decoder_dense = Dense(len(tokenizer_en.word_index)+1, activation='softmax') # 각각의 단어일 확률들이 쭉 나온다.\n",
        "decoder_softmax_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBJDA4pQ1W7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "08eac955-53f3-4289-b7ae-e58f05e83321"
      },
      "source": [
        "# 컴파일 진행\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "\n",
        "# sparse는 라벨이 정수 형태로 제공될 때 사용되는 함수 (그냥 categorical은 원핫 벡터로 라벨이 제공될 때)\n",
        "# 손실 함수에 sparse_ 를 쓰면 각각의 정수 인코딩 그대로 / 그냥 categorical_은 원 핫 인코딩으로 다시 변환\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# 모델 자체가 아닌 레이어 별로 가중치가 학습되는 것이다. (예측에서 다시 학습할 필요 X)\n",
        "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_output_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_output_test), batch_size = 128, epochs = 10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "279/279 [==============================] - 63s 226ms/step - loss: 3.4303 - acc: 0.6887 - val_loss: 2.2802 - val_acc: 0.6918\n",
            "Epoch 2/10\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.9869 - acc: 0.7287 - val_loss: 2.1965 - val_acc: 0.6973\n",
            "Epoch 3/10\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.9184 - acc: 0.7369 - val_loss: 2.1419 - val_acc: 0.7042\n",
            "Epoch 4/10\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.8634 - acc: 0.7407 - val_loss: 2.1040 - val_acc: 0.7058\n",
            "Epoch 5/10\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.8186 - acc: 0.7432 - val_loss: 2.0643 - val_acc: 0.7092\n",
            "Epoch 6/10\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.7767 - acc: 0.7464 - val_loss: 2.0258 - val_acc: 0.7125\n",
            "Epoch 7/10\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.7351 - acc: 0.7518 - val_loss: 2.0018 - val_acc: 0.7156\n",
            "Epoch 8/10\n",
            "279/279 [==============================] - 62s 222ms/step - loss: 1.7029 - acc: 0.7547 - val_loss: 1.9791 - val_acc: 0.7187\n",
            "Epoch 9/10\n",
            "279/279 [==============================] - 62s 221ms/step - loss: 1.6764 - acc: 0.7571 - val_loss: 1.9714 - val_acc: 0.7206\n",
            "Epoch 10/10\n",
            "279/279 [==============================] - 61s 220ms/step - loss: 1.6504 - acc: 0.7604 - val_loss: 1.9542 - val_acc: 0.7220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdf7f901438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKNIL-b_zaoI",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRlItsYczV63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더가 출력하는 마지막 시점의 셀/은닉 상태 값 따로 구하고\n",
        "# <start> 라는 인풋을 따로 디코더 모델의 LSTM에 집어넣은 후,\n",
        "# LSTM에서 나오는 아웃풋을 다시 LSTM에 계속 집어넣는 형태로 반복\n",
        "# 그러다가 <end>가 보이면 예측 중단"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6JvSJjH1OFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더가 출력하는 마지막 시점의 셀/은닉 상태 값을 따로 구하고, h_state, c_state는 아웃풋 레이어 (LSTM) 를 명시한 것\n",
        "# encoder_inputs과 encoder_input는 서로 다른 것 / encoder_inputs , h_state, c_state는 위에서 명시했던 것 사용\n",
        "# 훈련을 하고 나면 레이어 별로 가중치를 학습하기 때문에, 이미 훈련으로 학습된 가중치를 가진 레이어를 그대로 사용 \n",
        "encoder_model = Model(encoder_inputs, [h_state, c_state])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfa6vDu_2OWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더 모델을 만드는데, 디코더 모델에 초기값으로 넣을 상태값의 모양을 지정\n",
        "encoder_h_state = Input(shape=(50,))\n",
        "encoder_c_state = Input(shape=(50,))\n",
        "\n",
        "# 우리가 시퀀스를 넣을게 아니라 단어단어를 넣을거기 때문에, 시점이 여러개가 아니라 한 시점만 존재\n",
        "# 상태값을 자동으로 넘겨주지 않기 때문에 (순환 X), 직접 넘겨줘야한다. -> 셀 마다마다 상태의 초기값을 지정, 나오는 상태값을 저장\n",
        "pd_decoder_outputs, pd_h_state, pd_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_h_state, encoder_c_state])\n",
        "pd_decoder_softmax_outputs = decoder_dense(pd_decoder_outputs)\n",
        "\n",
        "# 모델은 디코더 인풋 (<start>) 과 인코더의 상태값이 인풋으로 들어간다.\n",
        "# LSTM 셀 통과하면서 예측하여 'softmax 함수를 통과한 출력값 (각 단어별 다음 단어일 확률값)', '디코더의 상태값' 두 개를 출력하는 것\n",
        "# softmax 함수를 통과한 출력값 (확률) 을 토대로 다음 단어를 확정\n",
        "# 다시 그 단어를 디코더 인풋으로 + 전 시점의 디코더의 상태값이 인풋으로 들어간다.\n",
        "decoder_model = Model([decoder_inputs] + [encoder_h_state, encoder_c_state], [pd_decoder_softmax_outputs] + [pd_h_state, pd_c_state])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ6_XMsqBuam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8f995c14-e13d-444c-d04c-465c606347c6"
      },
      "source": [
        "# '한글 문장 -> 영어 문장' 예측 (학습이 부족하여 정확도가 매우 낮음)\n",
        "\n",
        "input_stc = input()\n",
        "token_stc = input_stc.split()\n",
        "encode_stc = tokenizer_ko.texts_to_sequences([token_stc])\n",
        "pad_stc = pad_sequences(encode_stc, maxlen=27, padding=\"post\")\n",
        "\n",
        "# 인코더의 마지막 시점의 셀/은닉 상태 값\n",
        "states_value = encoder_model.predict(pad_stc)\n",
        "\n",
        "# <start> 를 정수 인코딩해서 numpy array 로\n",
        "predicted_seq = np.zeros((1,1))\n",
        "predicted_seq[0, 0] = en_to_index['<start>']\n",
        "\n",
        "# 각 시점마다 예측된 단어를 저장\n",
        "decoded_stc = []\n",
        "\n",
        "while True:\n",
        "    output_words, h, c = decoder_model.predict([predicted_seq] + states_value)\n",
        "\n",
        "    predicted_word = index_to_en[np.argmax(output_words[0,0])]  \n",
        "\n",
        "    if predicted_word == '<end>':\n",
        "        break\n",
        "\n",
        "    decoded_stc.append(predicted_word)\n",
        "\n",
        "    # 처음에는 <start>, 지금은 예측된 단어가 있으니 이것을 인풋으로 넣어주기 위해서 변수의 값을 업데이트\n",
        "    predicted_seq = np.zeros((1,1))\n",
        "    predicted_seq[0, 0] = np.argmax(output_words[0,0])\n",
        "\n",
        "    # 지금 시점의 상태 값을 다음 시점으로 넘기기 위해서 변수를 업데이트\n",
        "    # WARNING이 나오는 이유는, Prediction은 단어를 하나씩 넣으며 다음 단어를 예측하는데 27로 설정한 모델을 그대로 사용했기 때문\n",
        "    states_value = [h, c]\n",
        "\n",
        "print(' '.join(decoded_stc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "오늘은 날씨가 좋다\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 27) for input Tensor(\"input_2:0\", shape=(None, 27), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "the door is a good\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}