{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"summarize.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_faLwbaF_kVd","colab_type":"text"},"source":["attention.py 출처 : https://github.com/thushv89/attention_keras"]},{"cell_type":"code","metadata":{"id":"l5WDEMdH7cQ-","colab_type":"code","colab":{}},"source":["import numpy as np\n","import re\n","import pandas as pd\n","import csv\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whBWEzJ792OH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1597744756902,"user_tz":-540,"elapsed":24121,"user":{"displayName":"한지호","photoUrl":"","userId":"10290358644250020516"}},"outputId":"ab959e65-ddf0-4145-a6a5-5e92d875788d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2pNWEU4pvLhf","colab_type":"code","colab":{}},"source":["reviews = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/ai_school/data/Musical_instruments_reviews.csv\")\n","\n","reviews = reviews.loc[:, ['reviewText', 'summary']]\n","reviews = reviews.dropna(axis=0)\n","\n","reviews['reviewText'] = reviews['reviewText'].str.lower()\n","reviews['reviewText'] = reviews['reviewText'].str.replace('[^\\w]', ' ')\n","\n","reviews['summary'] = reviews['summary'].str.lower()\n","reviews['summary'] = reviews['summary'].str.replace('[^\\w]', ' ')\n","\n","print(reviews)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cwXaXSuiyPzD","colab_type":"code","colab":{}},"source":["encoder_input, decoder_input, decoder_output = [], [], []\n","\n","for stc in reviews['reviewText']:\n","    encoder_input.append(stc.split())\n","\n","for stc in reviews['summary']:\n","    decoder_input.append((\"<start> \"+stc).split())\n","\n","for stc in reviews['summary']:\n","    decoder_output.append((stc+\" <end>\").split())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvSbm_IDygwi","colab_type":"code","colab":{}},"source":["tokenizer_re = Tokenizer()\n","tokenizer_re.fit_on_texts(encoder_input)\n","encoder_input = tokenizer_re.texts_to_sequences(encoder_input)\n","\n","tokenizer_su = Tokenizer()\n","tokenizer_su.fit_on_texts(decoder_input)\n","tokenizer_su.fit_on_texts(decoder_output)\n","decoder_input = tokenizer_su.texts_to_sequences(decoder_input)\n","decoder_output = tokenizer_su.texts_to_sequences(decoder_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LsBIpW0bytSK","colab_type":"code","colab":{}},"source":["encoder_input = pad_sequences(encoder_input, padding=\"post\")\n","decoder_input = pad_sequences(decoder_input, padding=\"post\")\n","decoder_output = pad_sequences(decoder_output, padding=\"post\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJL0AM0sywxC","colab_type":"code","colab":{}},"source":["print(encoder_input.shape)\n","print(decoder_input.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubaAhrqry1St","colab_type":"code","colab":{}},"source":["su_to_index = tokenizer_su.word_index\n","index_to_su = tokenizer_su.index_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YTvSq-uCy_p8","colab_type":"code","colab":{}},"source":["test_size = 2500\n","encoder_input_train = encoder_input[:-test_size]\n","decoder_input_train = decoder_input[:-test_size]\n","decoder_output_train = decoder_output[:-test_size]\n","\n","encoder_input_test = encoder_input[-test_size:]\n","decoder_input_test = decoder_input[-test_size:]\n","decoder_output_test = decoder_output[-test_size:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZ6_uUo0zKzk","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Concatenate\n","from tensorflow.keras.models import Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxX5CrIjzQwo","colab_type":"code","colab":{}},"source":["encoder_inputs = Input(shape=(2089,))\n","encoder_embed = Embedding(len(tokenizer_re.word_index)+1, 50)(encoder_inputs)\n","encoder_mask = Masking(mask_value=0)(encoder_embed)\n","# return sequences = True 를 통해서 어텐션을 구할 때 필요한 전체 시점의 히든 상태값을 리턴하도록!\n","encoder_outputs, h_state, c_state = LSTM(50, return_state=True, return_sequences=True)(encoder_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7g-5iTy3ztha","colab_type":"code","colab":{}},"source":["decoder_inputs = Input(shape=(27,))\n","decoder_embed = Embedding(len(tokenizer_su.word_index)+1, 50)(decoder_inputs)\n","decoder_mask = Masking(mask_value=0)(decoder_embed)\n","decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vkVCbfL1z3SY","colab_type":"code","colab":{}},"source":["from attention import AttentionLayer\n","\n","# 어텐션 레이어 객체 생성\n","attn_layer = AttentionLayer()\n","# attn_out는 어텐션 밸류 (가중치가 보정된 인코더의 은닉 상태값의 합), attn_states는 가중치 \n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n","# 디코더의 히든상태랑 어텐션 밸류를 결합해서 새로운 출력 벡터 구함\n","decoder_concat_input = Concatenate()([decoder_outputs, attn_out])\n","\n","decoder_dense = Dense(len(tokenizer_su.word_index)+1, activation='softmax')\n","decoder_softmax_outputs = decoder_dense(decoder_concat_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lg6exLfr0mne","colab_type":"code","colab":{}},"source":["model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n","model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n","model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_output_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_output_test), batch_size = 128, epochs = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5HtEPcK0pmt","colab_type":"code","colab":{}},"source":["# 어텐션 계산을 위해 출력으로 encoder_outputs 까지!\n","encoder_model = Model(encoder_inputs, [encoder_outputs, h_state, c_state])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S9XKI-pu17E4","colab_type":"code","colab":{}},"source":["encoder_h_state = Input(shape=(50,))\n","encoder_c_state = Input(shape=(50,))\n","\n","pd_decoder_outputs, pd_h_state, pd_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_h_state, encoder_c_state])\n","\n","# 어텐션\n","# 2089는 시점 (단어, 패딩) 의 수, 50은 히든 스테이트의 차원\n","pd_encoder_outputs = Input(shape=(2089, 50))\n","pd_attn_out, pd_attn_states = attn_layer([pd_encoder_outputs, pd_decoder_outputs])\n","pd_decoder_concat = Concatenate()([pd_decoder_outputs, pd_attn_out])\n","\n","pd_decoder_softmax_outputs = decoder_dense(pd_decoder_concat)\n","\n","# 어텐션은 디코더 모델 안에서 사용하는거기 때문에, 인풋으로 encoder outputs 까지 넣어준다!\n","decoder_model = Model([decoder_inputs, pd_encoder_outputs, encoder_h_state, encoder_c_state], [pd_decoder_softmax_outputs, pd_h_state, pd_c_state])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWR4Zj_D3byP","colab_type":"code","colab":{}},"source":["input_stc = input()\n","token_stc = input_stc.split()\n","encode_stc = tokenizer_re.texts_to_sequences([token_stc])\n","pad_stc = pad_sequences(encode_stc, maxlen=2089, padding=\"post\")\n","\n","# 출력이 3가지 (전체 시점의 히든 상태값, 마지막 시점의 히든/셀 상태 값) 가 나온다\n","en_out, en_hidden, en_cell = encoder_model.predict(pad_stc)\n","\n","predicted_seq = np.zeros((1,1))\n","predicted_seq[0, 0] = su_to_index['<start>']\n","\n","decoded_stc = []\n","\n","while True:\n","    # 여기서 인풋으로 en_out 도 같이 넣어준다!\n","    output_words, h, c = decoder_model.predict([predicted_seq, en_out, en_hidden, en_cell])\n","\n","    predicted_word = index_to_su[np.argmax(output_words[0,0])]\n","\n","    if predicted_word == '<end>':\n","        break\n","\n","    decoded_stc.append(predicted_word)\n","\n","    predicted_seq = np.zeros((1,1))\n","    predicted_seq[0, 0] = np.argmax(output_words[0, 0])\n","\n","    en_hidden = h\n","    en_cell = c\n","\n","print(' '.join(decoded_stc))"],"execution_count":null,"outputs":[]}]}