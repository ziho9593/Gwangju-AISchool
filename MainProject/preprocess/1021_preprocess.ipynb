{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1021_preprocess.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDhC8L746PB1"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3PICZA2typr",
        "outputId": "97a4786e-82f3-4e64-bfb9-d9a82badfa7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "!pip install pandas\n",
        "!pip install sentencepiece\n",
        "!pip install hgtk\n",
        "!pip install gluonnlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 1.1MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n",
            "Collecting hgtk\n",
            "  Downloading https://files.pythonhosted.org/packages/79/04/04758ed8c086fb1d9a5a267f90239533d33dbc1646ac32f8bf80e38b0ec7/hgtk-0.1.3.tar.gz\n",
            "Building wheels for collected packages: hgtk\n",
            "  Building wheel for hgtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hgtk: filename=hgtk-0.1.3-py2.py3-none-any.whl size=6688 sha256=90829c1abb57e4fece62d374291acbe8ac91b59ffeca4a3e6a61dcfc0a4d9072\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/72/06/6065a57fe68264f35d7e52e37f56831eb3e9ec75656880de20\n",
            "Successfully built hgtk\n",
            "Installing collected packages: hgtk\n",
            "Successfully installed hgtk-0.1.3\n",
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.21)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp36-cp36m-linux_x86_64.whl size=588518 sha256=442ed09c75a6f7d6925401908027703ee2347a2f6be2a9e3a18a70cd07a930ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCNLZDGU2GAP"
      },
      "source": [
        "## Base Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Aj0XoF42ISW"
      },
      "source": [
        "def file_num_padding(file_num) :\n",
        "    if file_num < 10 :\n",
        "        return '00000' + str(file_num)\n",
        "    elif file_num < 100 :\n",
        "        return '0000' + str(file_num)\n",
        "    elif file_num < 1000 :\n",
        "        return '000' + str(file_num)\n",
        "    elif file_num < 10000 :\n",
        "        return '00' + str(file_num)\n",
        "    elif file_num < 100000 :\n",
        "        return '0' + str(file_num)\n",
        "    else :\n",
        "        return str(file_num)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP2LwzZK22Wq"
      },
      "source": [
        "def get_path(path, fname, file_num, format):\n",
        "    return path + fname +file_num + format"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZExgQ1u3BgT",
        "outputId": "e4bcfffb-9cd1-45de-d1fd-ce64f37782c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "BASE_PATH = './content/drive/My Drive/googledrive/'\n",
        "fname = 'KsponSpeech_'\n",
        "file_num = 1\n",
        "format = '.txt'\n",
        "\n",
        "print(get_path(BASE_PATH, fname, file_num_padding(file_num), format))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./content/drive/My Drive/googledrive/KsponSpeech_000001.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYqA2jpRBhsl"
      },
      "source": [
        "## preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sWnh2ZO_-p5"
      },
      "source": [
        "import os\n",
        "import re"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl08QiPaCGe5",
        "outputId": "2c69f53a-4941-4a08-8ed5-dabeef02861d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# mode = spelling(e.g., 70%는 칠십퍼센트 이렇게 표기되는 게 아니라 70%로 표기되도록)\n",
        "def bracket_filter(sentence):\n",
        "    # new_sentence = str()\n",
        "    new_sentence = \"\"\n",
        "    flag = True\n",
        "\n",
        "    for ch in sentence :\n",
        "        if ch == '(' :\n",
        "            continue\n",
        "\n",
        "        if ch == ')' :\n",
        "            if flag is True :\n",
        "                flag = False\n",
        "                continue\n",
        "            else :\n",
        "                flag = True\n",
        "                continue\n",
        "\n",
        "        if ch != ')' and flag is True :\n",
        "            new_sentence += ch\n",
        "\n",
        "            elif not skip :\n",
        "                new_sentence += ch\n",
        "\n",
        "        return new_sentence"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-ec059dc386a0>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    elif mode == 'spelling' :\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv5j2W1NWGQo"
      },
      "source": [
        "## Special Filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdrLDLUWHIDU"
      },
      "source": [
        "def special_filter(sentence, mode='phonetic', replace=None):\n",
        "    SENTENCE_MARK = ['?', '!', '.']\n",
        "\n",
        "    # noise라고 인식하면 안 되는 것들 추려내기!\n",
        "    NOISE = ['o', 'n', 'u', 'b', 'l']\n",
        "    EXCEPT = ['/', '+', '*', '-', '@', '$', '^', '&', '[', ']', '=', ':', ';', ',']\n",
        "\n",
        "    new_sentence = str()\n",
        "    for idx, ch in enumerate(sentence):\n",
        "        if ch not in SENTENCE_MARK:\n",
        "            if idx + 1 < len(sentence) and ch in NOISE and sentence[idx + 1] == '/':\n",
        "                continue\n",
        "\n",
        "        if ch == '#':\n",
        "            new_sentence += '샾'\n",
        "\n",
        "        elif ch == '%':\n",
        "            if mode == 'phonetic':\n",
        "                new_sentence += replace\n",
        "            elif mode == 'spelling':\n",
        "                new_sentence += '%'\n",
        "\n",
        "        elif ch not in EXCEPT:\n",
        "            new_sentence += ch\n",
        "\n",
        "    pattern = re.compile(r'\\s\\s+')\n",
        "    new_sentence = re.sub(pattern, ' ', new_sentence.strip())\n",
        "    return new_sentence\n",
        "\n",
        "\n",
        "def sentence_filter(raw_sentence, mode, replace=None):\n",
        "    return special_filter(bracket_filter(raw_sentence, mode), mode, replace)\n",
        "\n",
        "\n",
        "def preprocess(dataset_path, new_path, mode='phonetic'):\n",
        "    print('preprocess started..')\n",
        "\n",
        "    percent_files = {\n",
        "        '087797': '퍼센트',\n",
        "        '215401': '퍼센트',\n",
        "        '284574': '퍼센트',\n",
        "        '397184': '퍼센트',\n",
        "        '501006': '프로',\n",
        "        '502173': '프로',\n",
        "        '542363': '프로',\n",
        "        '581483': '퍼센트'\n",
        "    }\n",
        "\n",
        "    for folder in os.listdir(dataset_path):\n",
        "        # folder : {KsponSpeech_01, ..., KsponSpeech_05}\n",
        "        if not folder.startswith('KsponSpeech'):\n",
        "            continue\n",
        "        path = os.path.join(dataset_path, folder)\n",
        "        for idx, subfolder in enumerate(os.listdir(path)):\n",
        "            if idx == 0:\n",
        "                if not (os.path.isdir(os.path.join(new_path, folder))):\n",
        "                    os.makedirs(os.path.join(new_path, folder))\n",
        "            path = os.path.join(dataset_path, folder, subfolder)\n",
        "\n",
        "            for jdx, file in enumerate(os.listdir(path)):\n",
        "                if jdx == 0:\n",
        "                    if not (os.path.isdir(os.path.join(new_path, folder, subfolder))):\n",
        "                        os.makedirs(os.path.join(new_path, folder, subfolder))\n",
        "\n",
        "                if file.endswith('.txt'):\n",
        "                    with open(os.path.join(path, file), \"r\", encoding='cp949') as f:\n",
        "                        raw_sentence = f.read()\n",
        "                        if file[12:18] in percent_files.keys():\n",
        "                            new_sentence = sentence_filter(raw_sentence, mode, percent_files[file[12:18]])\n",
        "                        else:\n",
        "                            new_sentence = sentence_filter(raw_sentence, mode=mode)\n",
        "\n",
        "                    with open(os.path.join(new_path, folder, subfolder, file), \"w\", encoding='cp949') as f:\n",
        "                        f.write(new_sentence)\n",
        "\n",
        "                else:\n",
        "                    continue\n"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}