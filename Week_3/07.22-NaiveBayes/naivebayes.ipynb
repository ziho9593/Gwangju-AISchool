{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 광주 인공지능 사관학교\n",
    "- - -\n",
    "- 작성자 : 2반 한지호\n",
    "- 작성일 : 20.07.22 수\n",
    "- 4교시 자연어 처리 시간에 진행한 나이브 베이즈 분류기 수업 자료\n",
    "- - -\n",
    "- 수정일 : 20.07.23 목\n",
    "- 금일 진도에 따른 start_validate, open_csv_validate 함수 추가 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from math import log, exp\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 목표는 P(긍정|사용자가 입력한 값), P(부정|사용자가 입력한 값)\n",
    "# P(긍정|사용자가 입력한 값) = P(사용자가 입력한 값|긍정) * P(긍정) / P(사용자가 입력한 값) -> 베이즈 정리\n",
    "# 사용자가 입력한 값 = test_data\n",
    "# 긍정 / 부정 (데이터셋) = train_data\n",
    "\n",
    "def start():\n",
    "    train_datas = open_csv() \n",
    "    test_data = input() \n",
    "    prob = naive_bayes(train_datas, test_data, 0.5, 0.5) \n",
    "\n",
    "    print(f'{test_data}가 부정적일 확률 : {prob[0]}, 긍정적일 확률 : {prob[1]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_csv():\n",
    "    f = open('IMDB Dataset.csv', 'r', encoding='utf-8') \n",
    "    csvreader = csv.reader(f) \n",
    "\n",
    "    pos_doc = []\n",
    "    neg_doc = []\n",
    "\n",
    "    next(csvreader) # 첫줄은 헤더라서 스킵\n",
    "    \n",
    "    for line in csvreader:\n",
    "        if line[1] == 'positive':\n",
    "            pos_doc.append(line[0])\n",
    "        else:\n",
    "            neg_doc.append(line[0])\n",
    "\n",
    "    train_datas = [[], []]\n",
    "    train_datas[0] = neg_doc\n",
    "    train_datas[1] = pos_doc\n",
    "\n",
    "    # 리스트 형태는 토큰화하기가 어렵기 때문에, 전부 조인을 통해서 하나의 문자열로 만들어준다\n",
    "    return [' '.join(train_datas[0]), ' '.join(train_datas[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(test_data|긍정)\n",
    "# 동전 2개 던져서 앞면 앞면 -> 1/2 * 1/2\n",
    "# 긍정인 데이터셋이 있다. '최고 최고' -> 최고의 빈도수 / 전체 단어의 빈도수 * 최고의 빈도수 / 전체 단어의 빈도수\n",
    "# 어떤 문장 (test_data) -> 문장이 나올 확률 = 각 단어가 등장할 확률 다 곱한 것\n",
    "def calculate_doc_prob(train_data, test_data, nowords_weight):\n",
    "    # 스탑워드 제거\n",
    "    sw_train_data = re.compile('[^\\w]').sub(' ', train_data.lower())\n",
    "    # 토큰화\n",
    "    sw_train_token = sw_train_data.split()\n",
    "    # Bow화 (단어 : 빈도수 형태)\n",
    "    train_vector = dict(Counter(sw_train_token))\n",
    "\n",
    "    # 스탑워드 제거\n",
    "    sw_test_data = re.compile('[^\\w]').sub(' ', test_data.lower())\n",
    "    # 토큰화\n",
    "    sw_test_token = sw_test_data.split()\n",
    "    # Bow화 (단어 : 빈도수 형태)\n",
    "    test_vector = dict(Counter(sw_test_token))\n",
    "\n",
    "    log_prob = 0\n",
    "\n",
    "    total_wc = len(sw_train_token)\n",
    "\n",
    "    # log(P(test_data|긍정(train_data)))\n",
    "    # 문장이 나올 확률 = 각 단어가 등장할 확률 다 곱한 것\n",
    "    # 단어 10개로 이루어진 문장, 각 단어가 나올 확률이 (10/500000) -> 문장이 나올 확률은 0.00000000000000000000000000000000000000001024\n",
    "    # 0.2e-50 -> 0으로 인식 -> 로그함수를 취하면 -50\n",
    "    for word in test_vector:\n",
    "        if word in train_vector:\n",
    "            log_prob += log(train_vector[word]/total_wc)\n",
    "        else:\n",
    "            # train 데이터셋에 없는 단어가 나오면... 해당 단어가 나올 확률 추정못함\n",
    "            # 없는 단어는 요정도~ 나왔다고 가정하자! -> nowords_weight\n",
    "            log_prob += log(nowords_weight/total_wc)\n",
    "\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(train_datas, test_data, pos_prob, neg_prob):\n",
    "    # P(긍정|test_data) = P(test_data|긍정) * P(긍정) / P(test_data)\n",
    "    test_pos_prob = calculate_doc_prob(train_datas[1], test_data, 0.1) + log(pos_prob) \n",
    "    # P(부정|test_data) = P(test_data|부정) * P(부정) / P(test_data)\n",
    "    test_neg_prob = calculate_doc_prob(train_datas[0], test_data, 0.1) + log(neg_prob) \n",
    "\n",
    "    # 10 : 5 -> 2 : 1\n",
    "    # 긍정, 부정의 상대적인 크기\n",
    "    # test_pos_prob (로그값) -> 로그값에서 지수값으로 변환해도 0\n",
    "    # test_neg_prob (로그값) -> 로그값에서 지수값으로 변환해도 0\n",
    "    # 로그함수 -> logex, 지수함수 -> e**x\n",
    "    # -200, -220 -> 0, 0 (지수화하면 너무 작은 값이라 컴퓨터가 0으로 인식하기 때문에 손실이 생김) \n",
    "    # -200, -220 -> 0, -20 -> (지수화) e**0 = 1, e**-20 = 0.000000001\n",
    "    # 로그값 != 확률, -13, -12 -> e배이상의 확률차이가난다는것 -13/(-13+-12), -12/(-13+-12)\n",
    "    # -13, 12 -> 1, 0.35 -> 1/1.35, 0.35/1.35\n",
    "    maxprob = max(test_neg_prob, test_pos_prob)\n",
    "    test_pos_prob -= maxprob\n",
    "    test_neg_prob -= maxprob\n",
    "    test_pos_prob = exp(test_pos_prob)\n",
    "    test_neg_prob = exp(test_neg_prob)\n",
    "    # 두 확률 값의 상대적인 비율\n",
    "    normalized_prob = [test_neg_prob/(test_pos_prob+test_neg_prob), test_pos_prob/(test_pos_prob+test_neg_prob)]\n",
    "\n",
    "    return normalized_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so bad\n",
      "so bad가 부정적일 확률 : 0.8345935948229825, 긍정적일 확률 : 0.16540640517701757\n"
     ]
    }
   ],
   "source": [
    "start() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_validate():\n",
    "    train_datas, test_datas = open_csv_validate()\n",
    "\n",
    "    # 트레인 데이터 (긍정, 부정) 을 바탕으로 긍정적인 문장을 검사 -> 긍정적인 확률 높으면\n",
    "    prob = naive_bayes(train_datas, test_datas[1], 0.5, 0.5)\n",
    "\n",
    "    print(f'긍정적인 문장이 부정적일 확률 : {prob[0]}, 긍정적일 확률 : {prob[1]}')\n",
    "\n",
    "    # 트레인 데이터 (긍정, 부정) 을 바탕으로 부정적인 문장을 검사 -> 부정적인 확률 높으면\n",
    "    prob = naive_bayes(train_datas, test_datas[0], 0.5, 0.5)\n",
    "\n",
    "    print(f'부정적인 문장이 부정적일 확률 : {prob[0]}, 긍정적일 확률 : {prob[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_csv_validate():\n",
    "    f = open('IMDB Dataset.csv', 'r', encoding='utf-8')\n",
    "    csvreader = csv.reader(f)\n",
    "\n",
    "    pos_doc = []\n",
    "    neg_doc = []\n",
    "\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        if line[1] == 'positive':\n",
    "            pos_doc.append(line[0])\n",
    "        else:\n",
    "            neg_doc.append(line[0])\n",
    "\n",
    "    train_datas = [[], []]\n",
    "    # 25000개에서 20000 : 5000\n",
    "    train_datas[0] = neg_doc[:20000]\n",
    "    train_datas[1] = pos_doc[:20000]\n",
    "    test_datas = [neg_doc[20000:], pos_doc[20000:]]\n",
    "\n",
    "    # 리스트 형태는 토큰화하기가 어렵기 때문에, 전부 조인을 해서 하나의 문자열로 만들어준다\n",
    "    return [' '.join(train_datas[0]), ' '.join(train_datas[1])], [' '.join(test_datas[0]), ' '.join(test_datas[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 문장이 부정적일 확률 : 0.0, 긍정적일 확률 : 1.0\n",
      "부정적인 문장이 부정적일 확률 : 1.0, 긍정적일 확률 : 0.0\n"
     ]
    }
   ],
   "source": [
    "start_validate() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
